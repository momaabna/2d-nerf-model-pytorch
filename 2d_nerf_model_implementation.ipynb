{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This repository contains the implementation of a 2D NERF (Neural Radiance Fields) model for image rendering using PyTorch in a Jupyter Notebook format. The model is designed to render images using a 9-layer Multi-Layer Perceptron (MLP) and sinusoidal position encoding (PE).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0l7dQmhCux8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iTxzPj53IsRR"
      },
      "outputs": [],
      "source": [
        "#importing needed liberaries\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import torch.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Configuration\n",
        "The model is configured with the following hyperparameters:"
      ],
      "metadata": {
        "id": "tavWoj4OwjuH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PRzfX0XUYCp"
      },
      "outputs": [],
      "source": [
        "#configuration Hyperparameters \n",
        "image_size = 100\n",
        "n_layers =9\n",
        "layer_units =256\n",
        "epochs =200\n",
        "lr =0.00001\n",
        "encoding_degree = 5\n",
        "batch_size = 32\n",
        "up_scale = 4\n",
        "momentum =0.5\n",
        "device ='cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWw_8GDDT-ui"
      },
      "outputs": [],
      "source": [
        "class SRM(nn.Module):\n",
        "    def __init__(self,n_layers,layer_units,encoding_degree=5,sinsuidal_activation=False,use_position_encoding=True):\n",
        "        super(SRM,self).__init__()\n",
        "        self.encoding_degree = encoding_degree\n",
        "        self.n_layers=n_layers\n",
        "        self.use_position_encoding =use_position_encoding\n",
        "        self.sinsuidal_activation=sinsuidal_activation\n",
        "        self.layer_units =layer_units\n",
        "        if use_position_encoding :\n",
        "            self.input = nn.Linear(4*encoding_degree,layer_units)\n",
        "        else:\n",
        "            self.input = nn.Linear(2,layer_units)\n",
        "        self.layers =nn.ModuleList([nn.Linear(self.layer_units,self.layer_units) for _ in range(self.n_layers) ])\n",
        "        self.output =nn.Linear(self.layer_units,3) #RGB\n",
        "        \n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.out_act =nn.Softmax()\n",
        "\n",
        "    def forward(self,x):\n",
        "        if self.use_position_encoding:\n",
        "\n",
        "            l =[]\n",
        "            for i in range(self.encoding_degree):\n",
        "                l+=[torch.sin(2**i*np.pi*x[:,0].unsqueeze(1)),torch.cos(2**i*np.pi*x[:,0].unsqueeze(1))]\n",
        "                l+= [torch.sin(2**i*np.pi*x[:,1].unsqueeze(1)),torch.cos(2**i*np.pi*x[:,1].unsqueeze(1))] \n",
        "            #for i in range(self.encoding_degree):\n",
        "            #    pass\n",
        "\n",
        "            embeded = torch.concat(l,dim=-1)\n",
        "            z = self.input(embeded)\n",
        "        else:\n",
        "            z = self.input(x)\n",
        "        for l in self.layers:\n",
        "            if self.sinsuidal_activation:\n",
        "                z =torch.sin(l(z))\n",
        "            else:\n",
        "                z =self.activation(l(z)) \n",
        "        return self.output(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss_N0laCJt28",
        "outputId": "9a4462a7-729c-442a-c0b6-bd6c57dc331d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 3])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model =SRM(n_layers,layer_units,encoding_degree,sinsuidal_activation=True,use_position_encoding=True)\n",
        "x = torch.randn([10,2])\n",
        "\n",
        "model(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em4ROvX-1zPa"
      },
      "outputs": [],
      "source": [
        "!wget -O image.jpg https://unsplash.com/photos/J7fxkhtOqt0/download?force=true&w=640 \n",
        "!mogrify -resize 100x100! image.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKl2m8NVNYWE"
      },
      "outputs": [],
      "source": [
        "def generator(batch):\n",
        "    image = cv2.imread('image.jpg')\n",
        "    x = []\n",
        "    y = []\n",
        "    rr =[s for s in range(image_size)]\n",
        "    random.shuffle(rr)\n",
        "    while True:\n",
        "        for i in rr:\n",
        "            for j in rr:\n",
        "                x.append([i,j])\n",
        "                y.append(image[i,j])\n",
        "                if len(x)==batch:\n",
        "                    yield (np.array(x,dtype=np.float32)/image_size,np.array(y,dtype=np.float32))\n",
        "                    x=[]\n",
        "                    y=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0u548uPitQV"
      },
      "outputs": [],
      "source": [
        "criterion =nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=lr,momentum=momentum)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stcjH2ujta9a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def display(model):\n",
        "    x,y =np.meshgrid(np.linspace(0,image_size,image_size),np.linspace(0,image_size,image_size))\n",
        "    indexs = np.concatenate([y.reshape([image_size*image_size,1]),x.reshape([image_size*image_size,1])],axis=1)\n",
        "    ys =model(torch.from_numpy(indexs.astype(np.float32)/image_size))\n",
        "    image_g =np.reshape(ys.detach().numpy(),[image_size,image_size,3])\n",
        "    \n",
        "    img =cv2.imread('image.jpg')\n",
        "    img2 =cv2.imread('image2.jpg')\n",
        "\n",
        "    plt.figure(figsize=(16,3))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title('Original Image.')\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(image_g.astype(np.uint8))\n",
        "    plt.title('Memorized Image by MLP Model.')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_5xrZVEiA-M"
      },
      "outputs": [],
      "source": [
        "g =generator(batch_size)\n",
        "t =tqdm(total=epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    losses =0\n",
        "    model.to(device)\n",
        "    for i in range(image_size**2//batch_size):\n",
        "        x,y = next(g)\n",
        "        x = torch.from_numpy(x).to(device)\n",
        "        y = torch.from_numpy(y).to(device)\n",
        "        y1 = model(x)\n",
        "        loss = criterion(y1,y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    losses=loss.cpu().detach().numpy()\n",
        "    t.update()\n",
        "    \n",
        "        #t.display(f\"Epoch : {i},loss :{sum(losses)/(i+1)} , Done : {i/image_size**2//batch_size}\")\n",
        "    #if i%10000:\n",
        "    t.close()\n",
        "    if epoch%50==0:\n",
        "        display(model.cpu() )\n",
        "    print(f\"Epoch : {epoch},loss :{losses} \")#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if needed"
      ],
      "metadata": {
        "id": "8o5t_icexFv8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ-xKVTblArn"
      },
      "outputs": [],
      "source": [
        "!apt-get install imagemagick"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}